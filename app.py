# -*- coding: utf-8 -*-
"""app

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rhtOJG6mH9jh2pKTCbnSHhcaCnxNj7va
"""

import streamlit as st
import torch
import torch.nn as nn
import numpy as np
import joblib
import pandas as pd
from geopy.geocoders import Nominatim
from geopy.exc import GeocoderUnavailable, GeocoderTimedOut

# Define your NN model class (same as training)
class HousePriceNN(nn.Module):
    def __init__(self, input_size, hidden_sizes=[512, 256, 128, 64], dropout_rate=0.3):
        super(HousePriceNN, self).__init__()
        layers = []
        layers.append(nn.Linear(input_size, hidden_sizes[0]))
        layers.append(nn.ReLU())
        layers.append(nn.BatchNorm1d(hidden_sizes[0]))
        layers.append(nn.Dropout(dropout_rate))
        for i in range(len(hidden_sizes) - 1):
            layers.append(nn.Linear(hidden_sizes[i], hidden_sizes[i + 1]))
            layers.append(nn.ReLU())
            layers.append(nn.BatchNorm1d(hidden_sizes[i + 1]))
            layers.append(nn.Dropout(dropout_rate))
        layers.append(nn.Linear(hidden_sizes[-1], 1))
        self.network = nn.Sequential(*layers)

    def forward(self, x):
        return self.network(x)

# Load saved preprocessing tools and model
scaler_X = joblib.load("scaler_X.pkl")
scaler_y = joblib.load("scaler_y.pkl")
feature_columns = joblib.load("feature_columns.pkl")

input_size = len(feature_columns)

model = HousePriceNN(input_size)
model.load_state_dict(torch.load("model_state_dict.pth", map_location=torch.device("cpu")))
model.eval()

# App UI
st.title("üè° California House Price Predictor (NN Model)")

st.subheader("üìç Property Address")
street = st.text_input("Street Address")
city = st.text_input("City")
state = st.text_input("State")
zipcode = st.text_input("ZIP Code")

st.subheader("üè† Property Details")
living_area = st.number_input("Living Area (sqft)", min_value=200.0, max_value=10000.0, value=1500.0)
bedrooms = st.number_input("Bedrooms", min_value=0, max_value=10, value=3)
bathrooms = st.number_input("Bathrooms", min_value=0, max_value=10, value=2)
lot_size = st.number_input("Lot Size (Acres)", min_value=0.0, max_value=5.0, value=0.25)
year_built = st.number_input("Year Built", min_value=1900, max_value=2025, value=1980)
fireplaces = st.number_input("Fireplaces", min_value=0, max_value=5, value=1)
parking = st.number_input("Total Parking Spaces", min_value=0, max_value=10, value=2)
garage = st.number_input("Garage Spaces", min_value=0, max_value=5, value=1)
stories = st.selectbox("Stories", [1, 2, 3], index=0)
dom = st.number_input("Days on Market", min_value=0, value=30)

if st.button("Predict Price"):
    # Use geopy to get latitude and longitude from address
    full_address = f"{street}, {city}, {state} {zipcode}"
    geolocator = Nominatim(user_agent="house-price-predictor")
    
    try:
        location = geolocator.geocode(full_address, timeout=10)
    except (GeocoderTimedOut, GeocoderUnavailable) as e:
        st.error(f"Geocoding failed: {e}")
        st.stop()

    if location is None:
        st.error("Unable to find the location. Please check the address.")
        st.stop()

    latitude = location.latitude
    longitude = location.longitude

    # Prepare input dictionary
    input_dict = {
        'LivingArea': living_area,
        'BedroomsTotal': bedrooms,
        'BathroomsTotalInteger': bathrooms,
        'LotSizeAcres': lot_size,
        'YearBuilt': year_built,
        'FireplacesTotal': fireplaces,
        'ParkingTotal': parking,
        'GarageSpaces': garage,
        'Stories': stories,
        'DaysOnMarket': dom,
        'Latitude': latitude,
        'Longitude': longitude
    }

    # Initialize full feature vector with zeros
    input_vector = pd.Series(0, index=feature_columns)

    # Fill in numeric inputs
    for feature in input_dict:
        if feature in input_vector.index:
            input_vector[feature] = input_dict[feature]

    # TODO: Add categorical mappings if needed (e.g. City, County, etc.)

    # Scale
    try:
        input_array = input_vector.values.reshape(1, -1)
        X_scaled = scaler_X.transform(input_array)
    except Exception as e:
        st.error(f"Error during feature scaling: {e}")
        st.stop()

    # Predict
    X_tensor = torch.FloatTensor(X_scaled)
    with torch.no_grad():
        y_scaled_pred = model(X_tensor).item()
        y_pred = scaler_y.inverse_transform([[y_scaled_pred]])[0][0]

    # Display results
    st.success(f"üí∞ Estimated House Price: ${y_pred:,.2f}")
    st.info(f"üìç Geocoded Coordinates: Latitude {latitude:.6f}, Longitude {longitude:.6f}")
